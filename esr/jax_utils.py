"""
JAX utilities for ESR (Exhaustive Symbolic Regression)

This module provides utilities to convert SymPy expressions generated by ESR
into JAX functions that can be jitted and differentiated.
"""

import sympy
import jax
import jax.numpy as jnp
from jax import jit, grad, vmap
from typing import Callable, List, Union, Optional
import numpy as np

class SymPyToJAXConverter:
    """
    A class to handle conversion of SymPy expressions to JAX functions.
    """
    
    def __init__(self):
        # Mapping of SymPy functions to JAX equivalents
        self.function_map = {
            'sin': jnp.sin,
            'cos': jnp.cos,
            'tan': jnp.tan,
            'exp': jnp.exp,
            'log': jnp.log,
            'sqrt': jnp.sqrt,
            'Abs': jnp.abs,
            'abs': jnp.abs,
            'pow': jnp.power,
            'sinh': jnp.sinh,
            'cosh': jnp.cosh,
            'tanh': jnp.tanh,
            'asin': jnp.arcsin,
            'acos': jnp.arccos,
            'atan': jnp.arctan,
            'floor': jnp.floor,
            'ceil': jnp.ceil,
            'sign': jnp.sign,
        }
        
        # Custom functions that need special handling
        self.custom_functions = {
            'inv': lambda x: 1 / x,
            'square': lambda x: x**2,
            'cube': lambda x: x**3,
        }
    
    def convert(self, expr: sympy.Expr, variables: List[sympy.Symbol]) -> Callable:
        """
        Convert a SymPy expression to a JAX function.
        
        Args:
            expr: SymPy expression to convert
            variables: List of SymPy symbols that are the function variables
            
        Returns:
            JAX function that can be jitted and differentiated
        """
        try:
            # Try using sympy.lambdify with JAX modules
            modules = [self.function_map, self.custom_functions, 'jax']
            jax_func = sympy.lambdify(variables, expr, modules=modules)
            
            # Test the function to make sure it works
            test_args = [jnp.array(1.0) for _ in variables]
            try:
                result = jax_func(*test_args)
                if jnp.isfinite(result):
                    return jax_func
            except:
                pass
                
        except Exception as e:
            print(f"Warning: lambdify conversion failed: {e}")
        
        # Fallback to string-based conversion
        return self._convert_from_string(expr, variables)
    
    def _convert_from_string(self, expr: sympy.Expr, variables: List[sympy.Symbol]) -> Callable:
        """
        Fallback method to create JAX function from string representation.
        """
        expr_str = str(expr)
        
        # Replace SymPy function names with JAX equivalents
        for sympy_name, jax_func in self.function_map.items():
            expr_str = expr_str.replace(sympy_name, f'jnp.{jax_func.__name__}')
        
        # Handle custom functions
        for custom_name in self.custom_functions:
            if custom_name in expr_str:
                if custom_name == 'inv':
                    expr_str = expr_str.replace('inv(', '(1/(')
                elif custom_name == 'square':
                    expr_str = expr_str.replace('square(', '(')
                    expr_str = expr_str.replace(')', ')**2')
                elif custom_name == 'cube':
                    expr_str = expr_str.replace('cube(', '(')
                    expr_str = expr_str.replace(')', ')**3')
        
        # Create the function string
        var_names = [str(var) for var in variables]
        
        if len(var_names) == 1:
            func_str = f"lambda {var_names[0]}: {expr_str}"
        else:
            func_str = f"lambda {', '.join(var_names)}: {expr_str}"
        
        try:
            # Create local namespace with JAX functions
            local_ns = {'jnp': jnp, 'jax': jax}
            return eval(func_str, {"__builtins__": {}}, local_ns)
        except Exception as e:
            print(f"Warning: String conversion failed: {e}")
            # Return a safe default function
            if len(variables) == 1:
                return lambda x: x
            else:
                return lambda *args: args[0]

def create_jax_function_from_esr(func_string: str, 
                                 parameter_values: Optional[dict] = None) -> Callable:
    """
    Create a JAX function from an ESR function string.
    
    Args:
        func_string: String representation of the function from ESR
        parameter_values: Optional dictionary mapping parameter names to values
        
    Returns:
        JAX function that can be jitted and differentiated
    """
    # Set up SymPy symbols
    x = sympy.symbols('x', real=True)
    a_symbols = sympy.symbols([f'a{i}' for i in range(20)], real=True)
    
    # Define locals for sympy parsing
    locs = {
        'x': x, 
        'sin': sympy.sin, 
        'cos': sympy.cos, 
        'tan': sympy.tan,
        'exp': sympy.exp, 
        'log': sympy.log,
        'sqrt': sympy.sqrt,
        'Abs': sympy.Abs,
        'pow': sympy.Pow,
        'inv': lambda x: 1/x,
        'sinh': sympy.sinh,
        'cosh': sympy.cosh,
        'tanh': sympy.tanh,
    }
    
    # Add parameter symbols
    for i, a_sym in enumerate(a_symbols):
        locs[f'a{i}'] = a_sym
    
    try:
        # Parse the function string
        expr = sympy.sympify(func_string, locals=locs)
        
        # Substitute parameter values if provided
        if parameter_values:
            expr = expr.subs(parameter_values)
        
        # Convert to JAX
        converter = SymPyToJAXConverter()
        return converter.convert(expr, [x])
        
    except Exception as e:
        print(f"Error creating JAX function from '{func_string}': {e}")
        return lambda x: x  # Return identity function as fallback

def create_jax_optimizer_objective(expr_template: sympy.Expr, 
                                  param_symbols: List[sympy.Symbol],
                                  x_data: jnp.ndarray, 
                                  y_data: jnp.ndarray) -> Callable:
    """
    Create a JAX-optimized objective function for parameter fitting.
    
    Args:
        expr_template: SymPy expression with parameters to optimize
        param_symbols: List of parameter symbols in the expression
        x_data: Input data points
        y_data: Target output values
        
    Returns:
        JAX function that computes MSE loss for given parameters
    """
    converter = SymPyToJAXConverter()
    
    @jit
    def objective(params: jnp.ndarray) -> float:
        """
        Objective function that can be minimized.
        
        Args:
            params: Array of parameter values
            
        Returns:
            Mean squared error
        """
        # Create substitution dictionary
        param_dict = {param: params[i] for i, param in enumerate(param_symbols)}
        
        # Substitute parameters into expression
        expr_with_params = expr_template.subs(param_dict)
        
        # Convert to JAX function
        jax_func = converter.convert(expr_with_params, [sympy.Symbol('x')])
        
        # Compute predictions
        y_pred = jax_func(x_data)
        
        # Compute and return MSE
        return jnp.mean((y_pred - y_data) ** 2)
    
    return objective

def batch_evaluate_functions(function_strings: List[str], 
                            x_data: jnp.ndarray,
                            y_data: jnp.ndarray,
                            max_functions: Optional[int] = None) -> List[tuple]:
    """
    Evaluate multiple ESR functions in batch using JAX.
    
    Args:
        function_strings: List of function strings from ESR
        x_data: Input data for evaluation
        y_data: Target output data
        max_functions: Maximum number of functions to evaluate
        
    Returns:
        List of tuples (mse, function_string, jax_function)
    """
    if max_functions:
        function_strings = function_strings[:max_functions]
    
    results = []
    
    for func_str in function_strings:
        try:
            # Check if function has parameters and provide default values
            import sympy
            x = sympy.symbols('x', real=True)
            a_symbols = sympy.symbols([f'a{i}' for i in range(20)], real=True)
            
            locs = {'x': x, 'sin': sympy.sin, 'cos': sympy.cos, 'inv': lambda x: 1/x, 
                    'Abs': sympy.Abs, 'pow': sympy.Pow, 'exp': sympy.exp, 'log': sympy.log}
            
            for j, a_sym in enumerate(a_symbols):
                locs[f'a{j}'] = a_sym
            
            expr = sympy.sympify(func_str, locals=locs)
            param_symbols = [sym for sym in expr.free_symbols if str(sym).startswith('a')]
            
            # Provide default parameter values if needed
            parameter_values = {}
            if param_symbols:
                for param in param_symbols:
                    parameter_values[param] = 1.0  # Default value of 1.0
            
            # Create JAX function
            jax_func = create_jax_function_from_esr(func_str, parameter_values)
            
            # Evaluate function
            y_pred = jax_func(x_data)
            
            # Check for invalid values
            if jnp.any(jnp.isinf(y_pred)) or jnp.any(jnp.isnan(y_pred)):
                continue
            
            # Compute MSE
            mse = float(jnp.mean((y_pred - y_data) ** 2))
            
            results.append((mse, func_str, jax_func))
            
        except Exception as e:
            continue
    
    # Sort by MSE (best first)
    results.sort(key=lambda x: x[0])
    return results

def create_gradient_function(jax_func: Callable) -> Callable:
    """
    Create a gradient function from a JAX function.
    
    Args:
        jax_func: JAX function to differentiate
        
    Returns:
        JAX function that computes the gradient
    """
    return jit(grad(jax_func))

def create_higher_order_derivatives(jax_func: Callable, order: int = 2) -> List[Callable]:
    """
    Create higher-order derivative functions.
    
    Args:
        jax_func: JAX function to differentiate
        order: Maximum order of derivatives to compute
        
    Returns:
        List of derivative functions [f', f'', f''', ...]
    """
    derivatives = []
    current_func = jax_func
    
    for i in range(order):
        current_func = jit(grad(current_func))
        derivatives.append(current_func)
    
    return derivatives

# Example usage and demonstration functions
def demonstrate_jax_capabilities():
    """
    Demonstrate the JAX capabilities with a simple example.
    """
    print("Demonstrating JAX capabilities for ESR functions...")
    
    # Create a simple function
    func_str = "sin(x) * x + a0"
    param_values = {'a0': 0.5}
    
    # Convert to JAX
    jax_func = create_jax_function_from_esr(func_str, param_values)
    
    # Create test data
    x_test = jnp.linspace(0, 2*jnp.pi, 100)
    
    # Evaluate function
    y_test = jax_func(x_test)
    
    # Create gradient function
    grad_func = create_gradient_function(jax_func)
    grad_test = grad_func(x_test)
    
    print(f"Function: {func_str}")
    print(f"Function value at x=1: {jax_func(1.0):.6f}")
    print(f"Gradient at x=1: {grad_func(1.0):.6f}")
    
    return jax_func, grad_func

if __name__ == "__main__":
    demonstrate_jax_capabilities()
